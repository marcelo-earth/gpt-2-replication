# LLM Scaling Laws

So far we've learned that augmenting paramters, the data and computational resources, the performance of the model will improve in a predictable way. Basically diminishing returns.

- A huge model without enough data: Can't reach its potential
- A small model with a lot of data: Can't reach its potential

OK, this is so far for text models, but what about multimodal models?

## Multimodal Models


